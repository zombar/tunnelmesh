services:
  server:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: tunnelmesh-server
    hostname: server
    entrypoint: ["/bin/bash", "/scripts/server-entrypoint.sh"]
    volumes:
      - ./config/server.yaml:/etc/tunnelmesh/server.yaml:ro
      - ./scripts/server-entrypoint.sh:/scripts/server-entrypoint.sh:ro
      - metrics-data:/var/lib/tunnelmesh
      - s3-data:/var/lib/tunnelmesh/s3
      - server-keys:/root/.tunnelmesh  # Persist SSH keys across restarts
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker socket for container management
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    networks:
      mesh-control:
        ipv4_address: 172.28.0.10
    ports:
      - "8081:8080"   # Coordination API (peers connect here)
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8080/health"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 3s

  client:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    deploy:
      replicas: 5
    entrypoint: ["/bin/bash", "/scripts/client-entrypoint.sh"]
    volumes:
      - ./config/peer.yaml.template:/etc/tunnelmesh/peer.yaml.template:ro
      - ./scripts/client-entrypoint.sh:/scripts/client-entrypoint.sh:ro
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    depends_on:
      server:
        condition: service_started
    networks:
      - mesh-control
    environment:
      - SERVER_URL=http://172.28.0.10:8080
      - AUTH_TOKEN=docker-test-token-123
      - PING_INTERVAL=2
      - DISCOVERY_INTERVAL=20

  # Monitoring stack - shares server's network namespace for mesh access
  # Note: These use network_mode: "service:server" which binds to server's container.
  # The restart: true ensures they restart when server restarts/recreates.
  prometheus:
    image: prom/prometheus:latest
    container_name: tunnelmesh-prometheus
    # Share server's network namespace to access mesh IPs via TUN
    network_mode: "service:server"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.listen-address=:9090'
      - '--web.external-url=/prometheus/'
      - '--web.route-prefix=/prometheus/'
    volumes:
      - ../monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - ../monitoring/targets:/targets:ro
      - prometheus-data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/prometheus/-/ready"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    depends_on:
      server:
        condition: service_healthy
        restart: true
    restart: unless-stopped

  sd-generator:
    build:
      context: ..
      dockerfile: monitoring/sd_generator/Dockerfile
    container_name: tunnelmesh-sd-generator
    # Share server's network to reach coord API and resolve mesh DNS
    network_mode: "service:server"
    environment:
      - COORD_SERVER_URL=http://localhost:8080
      - AUTH_TOKEN=docker-test-token-123
      - POLL_INTERVAL=30s
      - OUTPUT_FILE=/targets/peers.json
      - METRICS_PORT=9443
      - TLS_SKIP_VERIFY=true
    volumes:
      - ../monitoring/targets:/targets
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    depends_on:
      server:
        condition: service_healthy
        restart: true
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: tunnelmesh-grafana
    # Share server's network namespace
    network_mode: "service:server"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=false
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_HTTP_PORT=3000
      - GF_SERVER_ROOT_URL=https://server-node.tunnelmesh/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/tunnelmesh.json
    volumes:
      - ../monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ../monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    depends_on:
      server:
        condition: service_healthy
        restart: true
      prometheus:
        condition: service_started
      loki:
        condition: service_started
    restart: unless-stopped

  loki:
    image: grafana/loki:latest
    container_name: tunnelmesh-loki
    # Share server's network namespace to receive logs from mesh peers
    network_mode: "service:server"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ../monitoring/loki/config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    healthcheck:
      # Use /metrics instead of /ready - single-instance Loki's readiness check can be flaky
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3100/metrics"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    depends_on:
      server:
        condition: service_healthy
        restart: true
    restart: unless-stopped

  benchmarker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.benchmarker
    container_name: tunnelmesh-benchmarker
    # Share server's network namespace to access mesh IPs via TUN
    network_mode: "service:server"
    environment:
      - COORD_SERVER_URL=http://localhost:8080
      - AUTH_TOKEN=docker-test-token-123
      - LOCAL_PEER=benchmarker
      - BENCHMARK_INTERVAL=30s       # Start new batch every 30s
      - BENCHMARK_CONCURRENCY=3      # 3 concurrent transfers per batch
      - BENCHMARK_SIZE=100MB
      - OUTPUT_DIR=/results
      - TLS_SKIP_VERIFY=true
      # Randomized chaos testing (enabled by default)
      # Each transfer randomly picks from presets: clean, subtle, lossy-wifi,
      # mobile-3g, mobile-4g, satellite, congested, bandwidth-10/50/100mbps
      # - RANDOMIZE_CHAOS=false      # Disable to run all clean benchmarks
    volumes:
      - benchmark-results:/results
    depends_on:
      server:
        condition: service_healthy
        restart: true
    restart: unless-stopped

networks:
  mesh-control:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/24

volumes:
  metrics-data:
    name: tunnelmesh-metrics-data
    labels:
      - "com.tunnelmesh.description=Stats history for dashboard charts"
  s3-data:
    name: tunnelmesh-s3-data
    labels:
      - "com.tunnelmesh.description=S3 storage for users, groups, and file shares"
  server-keys:
    name: tunnelmesh-server-keys
    labels:
      - "com.tunnelmesh.description=Server SSH keys for mesh join identity"
  prometheus-data:
  grafana-data:
  loki-data:
  benchmark-results:
